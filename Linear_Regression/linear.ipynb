{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName(\"Linear Reggression\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df=spark.read.csv(\"/home/hdoop/Downloads/Salary_Data.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|   YearsExperience|            Salary|\n",
      "+-------+------------------+------------------+\n",
      "|  count|                30|                30|\n",
      "|   mean|5.3133333333333335|           76003.0|\n",
      "| stddev| 2.837888157662718|27414.429784582302|\n",
      "|    min|               1.1|           37731.0|\n",
      "|    max|              10.5|          122391.0|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, YearsExperience: string, Salary: string]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- YearsExperience: double (nullable = true)\n",
      " |-- Salary: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+\n",
      "|YearsExperience| Salary|\n",
      "+---------------+-------+\n",
      "|            1.1|39343.0|\n",
      "|            1.3|46205.0|\n",
      "|            1.5|37731.0|\n",
      "|            2.0|43525.0|\n",
      "|            2.2|39891.0|\n",
      "|            2.9|56642.0|\n",
      "|            3.0|60150.0|\n",
      "|            3.2|54445.0|\n",
      "|            3.2|64445.0|\n",
      "|            3.7|57189.0|\n",
      "|            3.9|63218.0|\n",
      "|            4.0|55794.0|\n",
      "|            4.0|56957.0|\n",
      "|            4.1|57081.0|\n",
      "|            4.5|61111.0|\n",
      "|            4.9|67938.0|\n",
      "|            5.1|66029.0|\n",
      "|            5.3|83088.0|\n",
      "|            5.9|81363.0|\n",
      "|            6.0|93940.0|\n",
      "+---------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a vector form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[\"YearsExperience\"], outputCol=\"features\")\n",
    "\n",
    "# Assemble the features\n",
    "spark_df = assembler.transform(spark_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|   YearsExperience|            Salary|\n",
      "+-------+------------------+------------------+\n",
      "|  count|                30|                30|\n",
      "|   mean|5.3133333333333335|           76003.0|\n",
      "| stddev| 2.837888157662718|27414.429784582302|\n",
      "|    min|               1.1|           37731.0|\n",
      "|    max|              10.5|          122391.0|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+--------+\n",
      "|YearsExperience| Salary|features|\n",
      "+---------------+-------+--------+\n",
      "|            1.1|39343.0|   [1.1]|\n",
      "|            1.3|46205.0|   [1.3]|\n",
      "|            1.5|37731.0|   [1.5]|\n",
      "|            2.0|43525.0|   [2.0]|\n",
      "|            2.2|39891.0|   [2.2]|\n",
      "|            2.9|56642.0|   [2.9]|\n",
      "|            3.0|60150.0|   [3.0]|\n",
      "|            3.2|54445.0|   [3.2]|\n",
      "|            3.2|64445.0|   [3.2]|\n",
      "|            3.7|57189.0|   [3.7]|\n",
      "|            3.9|63218.0|   [3.9]|\n",
      "|            4.0|55794.0|   [4.0]|\n",
      "|            4.0|56957.0|   [4.0]|\n",
      "|            4.1|57081.0|   [4.1]|\n",
      "|            4.5|61111.0|   [4.5]|\n",
      "|            4.9|67938.0|   [4.9]|\n",
      "|            5.1|66029.0|   [5.1]|\n",
      "|            5.3|83088.0|   [5.3]|\n",
      "|            5.9|81363.0|   [5.9]|\n",
      "|            6.0|93940.0|   [6.0]|\n",
      "+---------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "train_df, test_df = spark_df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+--------+\n",
      "|YearsExperience| Salary|features|\n",
      "+---------------+-------+--------+\n",
      "|            1.1|39343.0|   [1.1]|\n",
      "|            2.2|39891.0|   [2.2]|\n",
      "|            3.7|57189.0|   [3.7]|\n",
      "|            3.9|63218.0|   [3.9]|\n",
      "|            4.0|56957.0|   [4.0]|\n",
      "|            5.3|83088.0|   [5.3]|\n",
      "|            5.9|81363.0|   [5.9]|\n",
      "+---------------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- YearsExperience: double (nullable = true)\n",
      " |-- Salary: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(test_df.count())\n",
    "l=len(test_df.columns)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(train_df.count())\n",
    "l=len(train_df.columns)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Linear reggression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/24 16:53:59 WARN Instrumentation: [1a1d9360] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    }
   ],
   "source": [
    "# Create the Linear Regression model\n",
    "regr = LinearRegression(featuresCol='features', labelCol='Salary', regParam=0.0, solver=\"normal\")\n",
    "\n",
    "# Fit the model to the training data\n",
    "regr_model = regr.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecting Salary By years of experince"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+\n",
      "|YearsExperience|        prediction|\n",
      "+---------------+------------------+\n",
      "|            1.1|37033.710931304675|\n",
      "|            2.2| 47292.89809276757|\n",
      "|            3.7|61282.698767489695|\n",
      "|            3.9|63148.005524119304|\n",
      "|            4.0| 64080.65890243412|\n",
      "|            5.3| 76205.15282052662|\n",
      "|            5.9| 81801.07309041548|\n",
      "+---------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = regr_model.transform(test_df)\n",
    "\n",
    "# Show the predicted values\n",
    "predictions.select(\"YearsExperience\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating The R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value: 0.9051905534419166\n"
     ]
    }
   ],
   "source": [
    "evaluator_r2 = RegressionEvaluator(labelCol=\"Salary\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "print(\"R-squared value:\", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
